<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
    <link rel="stylesheet" href="style.css" />
    <title>Embodied Interaction</title>
  </head>
  <body>
    <section class="header">
      <div class="degree-name">
        <div>Art + New Media</div>
        <div style="justify-self: end">2023</div>
      </div>
      <div class="student-name">Yan Zhang</div>
      <div class="student-bio">
        I love this page and these doggie images.But they will be replaced soon...
      </div>
    </section>
    <section class="content">
      <div class="course-name">Embodied Interaction</div>
      <!-- Copy-pate the post section under an exisiting section to create a new entry -->
      <section class="post">
        <!-- When writing the post title use the format dd.mm.yy Title -->
        <div class="post-title-date">Gesture Assignment (first meeting)</div>
        <div class="text-container">
          In this first discussion, we came up with many different and interesting 
          gestures, from the hand to the whole body. Some of the gestures were 
          given a certain social meaning, and they were often applied to person-to-
          person, person-to-social services, and some gestural habits developed by 
          existing technologies.
          <!-- Use two line breaks <br /> to create a new paragraph -->
          <br />
          <br />
          But other gestures with more potential are less socially relevant. 
          For example, cupping ear to hear more sounds, or putting 
          the hand to the forehead to block the sun, are gestures that respond to 
          the environment.
          <br />
          <br />
          And we come up with some new devices and occasion to apply these gestures 
          which only react to environment, natural substances (sound, wind, sunlight,
          waterâ€¦). For example, creating an immersive space to interpret natural scenes, 
          amplifying the volume when detect people try to get close with ear.
          <br>
          <br>
          <div class="post-title-date">Gesture Assignment (second meeting & Presentation)</div>
          <div class="text-container">
            In the second meeting we decided to focus on the cupping ear gesture. 
            And for the context of using, we thought we should respect the feature 
            of the gesture ---- react to the environment, which can also be said as 
            reacting to nature. 
            <br>
            <br>
            We abandoned the one-way directive interaction from human to 
            object and instead created a process --- an object affects people, stimulates 
            gesture response from the people, and eventually achieve to change the object. 
            <br>
            <br>
            For object, it should be an audio device in order to fit the logic of the 
            gesture. At first we decided to show a speaker under the spotlight, but considering 
            that people would touch it and do something unexpected, we considered adding a 
            fence in front of the speaker...
            At this point, it naturally occurred to us that we needed a contextual story to 
            make the overall process more vivid and meaningful.
            <br>
            <br>
            So we came up with an animal-related scenario. When people stand outside the fence 
            see a caged animal (object) struggling and opening its mouth to scream something; 
            Then people may come closer and cup ear to hear more, and the those sound becomes 
            clear.
            We thought that this gesture could also be used to make the image clearer, so 
            we set up a screen behind the cage which can show how free the animal is in nature.
            We discussed a lot about the rationality of people's motivations for this, making 
            each process more natural,what props to use and a determined a clear division of
            labour for the presentation.
            <br>
            <br>
            <br>
            We were assigned individual tasks and completed the final presentation.
            <br>
            <br>
            At the beginning of the discussion, I thought there was more expansion 
            in the natural environment of this gesture. But after watching the other 
            groups perform it, I understood that we got limitations. Because there 
            is also a human-design gap in interaction and technology in modern society, 
            there are still many modes of living together between human and AI for us 
            to explore.
            <br>
            <br>
            <br>
            <br>
            <iframe width="650" height="415" src="https://www.youtube.com/embed/V5TFZuwF8bM?controls=0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          </div>
          <br><br><br><br>
          <br><br><br><br>
          <br><br><br><br>
          <div class="post-title-date">Project Proposal</div>
          <iframe width="768" height="432" src="https://miro.com/app/live-embed/uXjVMfIarDU=/?moveToViewport=-1101,-931,5606,2481&embedId=229463644130" frameborder="0" scrolling="no" allow="fullscreen; clipboard-read; clipboard-write" allowfullscreen></iframe>

        </div>
        <div class="image-container">
          <!-- Put your images on the images folder and reference them here. Make sure to write an alt description -->
          <img class="image-style" src="images/firstmeeting.png" alt="" />
          <br>
         
          <img class="image-style" src="images/secondmeeting.png" alt="" />
          <br>
          <img class="image-style" src="images/working.jpg" alt="" />
          <img class="image-style" src="images/snake.jpg" alt="" />
        </div>
      </section>
      <section class="post">
        <div class="post-title-date">Project Documentry</div>
        <br>
        <br>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/Atn4wHS7qAY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
          
          <br />
          <br />
          I record a video to explain what's going on in the project.
        I used virtual midi to control both the visuals of touch designer and the sound of ableton.
The visual part of the touch designer is partly done by TDAbeton (mainly by automatically changing the effects according to the audio track) and partly by Midi input directly controlled by the virtual midi.
The Kinect is separate from the other parts, it detects the dancer's left and right hand positions and makes simple changes to the visuals such as noise, rotate etc.

          <br />
          <br />
          <br />
          <br />
          <br />
          <br />
          <iframe width="560" height="315" src="https://www.youtube.com/embed/kNjFUx_m9QY" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>
        </div>
        <div class="image-container">
        </div>
      </section>
      <section class="post">
        <div class="post-title-date">22.10.22 Post title</div>
        <div class="text-container">
          Labore esse Lorem laborum Lorem occaecat id. Culpa consequat nulla
          velit exercitation elit aute mollit sit eiusmod id occaecat. Voluptate
          consequat duis eiusmod ullamco excepteur irure officia dolor voluptate
          officia nulla dolor consequat amet. Non elit ex reprehenderit sint.
          Non sit sunt commodo nisi labore cupidatat duis duis velit nulla.
          Ipsum mollit eu est quis exercitation id et incididunt minim. Cillum
          aute laborum amet excepteur anim ad nulla eu magna enim proident.
          <br />
          <br />
          Aute tempor eu reprehenderit in ut esse anim incididunt aliquip et
          non. Eiusmod et reprehenderit proident consectetur. Consectetur et
          laboris in veniam veniam exercitation veniam labore duis ipsum elit
          esse occaecat cillum. Laborum voluptate Lorem voluptate do occaecat
          ipsum sunt. Ad laborum commodo mollit incididunt. Ullamco velit
          officia culpa et. Aliquip incididunt ea elit amet culpa sit eu dolore
          ullamco aliqua qui adipisicing occaecat.
          <br />
          <br />
          Veniam cupidatat aliqua in proident duis adipisicing aliqua duis.
          Fugiat cupidatat non tempor et eiusmod qui. Commodo Lorem irure
          exercitation non voluptate ipsum ut aute culpa. Reprehenderit
          reprehenderit nostrud sunt excepteur magna ipsum quis sint pariatur
          nisi esse et irure ipsum.
        </div>
        <div class="image-container">
          <img class="image-style" src="images/image-5.png" alt="A dog" />
          <img class="image-style" src="images/image-6.png" alt="A dog" />
        </div>
      </section>
    </section>
    <footer class="footer">Theme by Calvin 2022</footer>
  </body>
</html>
